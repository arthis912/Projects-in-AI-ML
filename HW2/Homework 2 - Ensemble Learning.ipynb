{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "260e3242",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc29656b",
   "metadata": {},
   "source": [
    "The dataset I am using: https://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand/data\n",
    "\n",
    "As I specified in Homework 1, the dataset is extremely large. So after all necessary EDA was complete, I radnomly chose 900 columns as a sample of the larger dataset. The file is pushed with this notebook called 'sample_hotel_bookings.xlsx.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c8cf1e",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d65b9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7394c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the local dataset\n",
    "path = 'sample_hotel_bookings.xlsx'\n",
    "data = pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa025401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>meal</th>\n",
       "      <th>market_segment</th>\n",
       "      <th>distribution_channel</th>\n",
       "      <th>reserved_room_type</th>\n",
       "      <th>assigned_room_type</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>...</th>\n",
       "      <th>babies</th>\n",
       "      <th>is_repeated_guest</th>\n",
       "      <th>previous_cancellations</th>\n",
       "      <th>previous_bookings_not_canceled</th>\n",
       "      <th>booking_changes</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>is_canceled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.127134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.584967</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.477337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.645447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.352469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.239628</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hotel  arrival_date_month  meal  market_segment  distribution_channel  \\\n",
       "0      1                  10     3               2                     2   \n",
       "1      1                   7     0               2                     2   \n",
       "2      1                   0     0               3                     2   \n",
       "3      1                   9     0               3                     2   \n",
       "4      0                   5     0               1                     1   \n",
       "\n",
       "   reserved_room_type  assigned_room_type  deposit_type  customer_type  \\\n",
       "0                   1                   1             0              0   \n",
       "1                   2                   2             0              0   \n",
       "2                   1                   1             0              0   \n",
       "3                   1                   2             0              2   \n",
       "4                   6                   8             0              0   \n",
       "\n",
       "   lead_time  ...  babies  is_repeated_guest  previous_cancellations  \\\n",
       "0   4.127134  ...     0.0           0.000000                     0.0   \n",
       "1   4.477337  ...     0.0           0.000000                     0.0   \n",
       "2   0.693147  ...     0.0           0.693147                     0.0   \n",
       "3   5.645447  ...     0.0           0.000000                     0.0   \n",
       "4   3.218876  ...     0.0           0.693147                     0.0   \n",
       "\n",
       "   previous_bookings_not_canceled  booking_changes  days_in_waiting_list  \\\n",
       "0                        0.000000              0.0                   0.0   \n",
       "1                        0.000000              0.0                   0.0   \n",
       "2                        1.609438              0.0                   0.0   \n",
       "3                        0.000000              0.0                   0.0   \n",
       "4                        1.386294              0.0                   0.0   \n",
       "\n",
       "        adr  required_car_parking_spaces  total_of_special_requests  \\\n",
       "0  4.584967                     0.693147                   0.693147   \n",
       "1  5.049856                     0.000000                   0.693147   \n",
       "2  3.828641                     0.000000                   0.693147   \n",
       "3  4.352469                     0.000000                   0.000000   \n",
       "4  5.239628                     0.693147                   1.386294   \n",
       "\n",
       "   is_canceled  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing the first few rows of the dataset to see all the features of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "54f53e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing X and y\n",
    "X = data.drop('is_canceled', axis=1).values\n",
    "y = data['is_canceled'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "43e94e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train 80% and Test 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b71fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize decision tree object\n",
    "classification_tree = tree.DecisionTreeClassifier()\n",
    "\n",
    "#Train our decision tree (tree induction + pruning)\n",
    "classification_tree = classification_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ebc6b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the predictions\n",
    "predictions = classification_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd8bef5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79       109\n",
      "           1       0.71      0.48      0.57        71\n",
      "\n",
      "    accuracy                           0.72       180\n",
      "   macro avg       0.71      0.68      0.68       180\n",
      "weighted avg       0.72      0.72      0.70       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the base model with no modifications\n",
    "base_accuracy = accuracy_score(y_test, predictions)\n",
    "base_report = classification_report(y_test, predictions)\n",
    "\n",
    "print(base_accuracy)\n",
    "print(base_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fbcff6",
   "metadata": {},
   "source": [
    "Modifying Max_Depth Parameter\n",
    "\n",
    "max_depth can prevent overfitting by keeping the model from getting too complex by memorizing the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "988a54ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7055555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.97      0.80       109\n",
      "           1       0.88      0.30      0.44        71\n",
      "\n",
      "    accuracy                           0.71       180\n",
      "   macro avg       0.78      0.63      0.62       180\n",
      "weighted avg       0.76      0.71      0.66       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#MAX_DEPTH = 5\n",
    "#Initialize decision tree object\n",
    "classification_tree = tree.DecisionTreeClassifier(max_depth = 5)\n",
    "\n",
    "#Train our decision tree (tree induction + pruning)\n",
    "classification_tree = classification_tree.fit(X_train, y_train)\n",
    "\n",
    "#Generating the predictions\n",
    "predictions = classification_tree.predict(X_test)\n",
    "\n",
    "#Evaluating the base model with no modifications\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "report = classification_report(y_test, predictions)\n",
    "\n",
    "print(accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e5085415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7222222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78       109\n",
      "           1       0.68      0.55      0.61        71\n",
      "\n",
      "    accuracy                           0.72       180\n",
      "   macro avg       0.71      0.69      0.70       180\n",
      "weighted avg       0.72      0.72      0.72       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#MAX_DEPTH = 10\n",
    "#Initialize decision tree object\n",
    "classification_tree = tree.DecisionTreeClassifier(max_depth = 10)\n",
    "\n",
    "#Train our decision tree (tree induction + pruning)\n",
    "classification_tree = classification_tree.fit(X_train, y_train)\n",
    "\n",
    "#Generating the predictions\n",
    "predictions = classification_tree.predict(X_test)\n",
    "\n",
    "#Evaluating the base model with no modifications\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "report = classification_report(y_test, predictions)\n",
    "\n",
    "print(accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e34684",
   "metadata": {},
   "source": [
    "Base Model\n",
    "- Accuracy: 0.717\n",
    "- Precision: 0.72, 0.71\n",
    "- Recall: 0.87, 0.48\n",
    "\n",
    "Max_depth = 5\n",
    "- Accuracy: 0.706\n",
    "- Precision: 0.68, 0.88\n",
    "- Recall: 0.97, 0.3\n",
    "\n",
    "Max_depth = 10\n",
    "- Accuracy: 0.722\n",
    "- Precision: 0.74, 0.68\n",
    "- Recall: 0.83, 0.55\n",
    "\n",
    "When changing the max_depth to 5, the accuracy slightly decreases from the base model. The values for precision are close to the base model with a slight fluctuation. The recall values are low for class 1, meaning that it does not as many cancelled reservations correctly. Limiting the depth to 5 makes the model slightly more conservative.\n",
    "\n",
    "When increasing the max_depth to 10, the accuracy increases. It also has the highest values for precision and recall. This means a more complex model would produce better results by understanding the datra better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82bb42",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fa059e",
   "metadata": {},
   "source": [
    "# Bagging - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "60566dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "300d6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing X and y\n",
    "X = data.drop('is_canceled', axis=1).values\n",
    "y = data['is_canceled'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7f53149a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest Model: 0.7666666666666666\n",
      "Precision: 0.7856113573250006\n",
      "Recall: 0.5508042279299817\n"
     ]
    }
   ],
   "source": [
    "#Intialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state = 5)\n",
    "\n",
    "#k-fold cross validation\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state = 5)\n",
    "\n",
    "#Getting metrics for the model\n",
    "rf_accuracy = np.mean(cross_val_score(rf_model, X, y, cv=kfold, scoring='accuracy'))\n",
    "rf_precision = np.mean(cross_val_score(rf_model, X, y, cv=kfold, scoring='precision'))\n",
    "rf_recall = np.mean(cross_val_score(rf_model, X, y, cv=kfold, scoring='recall'))\n",
    "\n",
    "print(\"Accuracy for Random Forest Model:\", rf_accuracy)\n",
    "print(\"Precision:\", rf_precision)\n",
    "print(\"Recall:\", rf_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586bfa05",
   "metadata": {},
   "source": [
    "# Boosting - AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dee0f70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for AdaBoost Model: 0.78\n",
      "Precision: 0.7810999052117473\n",
      "Recall: 0.6193630120340456\n"
     ]
    }
   ],
   "source": [
    "#Intialize the Random Forest model\n",
    "ada_model = AdaBoostClassifier(random_state = 5)\n",
    "\n",
    "#k-fold cross validation\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state = 5)\n",
    "\n",
    "#Getting metrics value for the model\n",
    "ada_accuracy = np.mean(cross_val_score(ada_model, X, y, cv=kfold, scoring='accuracy'))\n",
    "ada_precision = np.mean(cross_val_score(ada_model, X, y, cv=kfold, scoring='precision'))\n",
    "ada_recall = np.mean(cross_val_score(ada_model, X, y, cv=kfold, scoring='recall'))\n",
    "\n",
    "print(\"Accuracy for AdaBoost Model:\", ada_accuracy)\n",
    "print(\"Precision:\", ada_precision)\n",
    "print(\"Recall:\", ada_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e183cee",
   "metadata": {},
   "source": [
    "Both chosen ensemble models performed similarly and relatively well on the dataset. The AdaBoost model performed slightly better than the Random Forest model. In terms of precision, Random Forest performs better but by a very small margin. This means it is better at predicting the cancellations. For recall, AdaBoost has a higher value meaning that it is better at identifying the correct cancellations. Overall for the performance, it seems as though AdaBoost has an edge over the Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adab256",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c0e5f3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7166666666666667\n",
      "0.6724137931034483\n",
      "0.5492957746478874\n"
     ]
    }
   ],
   "source": [
    "#MAX_DEPTH = 10\n",
    "#Initialize decision tree object\n",
    "classification_tree = tree.DecisionTreeClassifier(max_depth = 10)\n",
    "\n",
    "#Train our decision tree (tree induction + pruning)\n",
    "classification_tree = classification_tree.fit(X_train, y_train)\n",
    "\n",
    "#Generating the predictions\n",
    "predictions = classification_tree.predict(X_test)\n",
    "\n",
    "#Evaluating the base model with no modifications\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f731fe",
   "metadata": {},
   "source": [
    "As described in task 2, the metrics I used was accuracy, precision and recall. \n",
    "\n",
    "Accuracy is a straightforward metric and is easily interpretable. It provides an insight into how often the models predicts the cancellation correctly.\n",
    "\n",
    "Accuracy\n",
    "- Decision Tree (max_depth 10): 0.72\n",
    "- Random Forest: 0.77\n",
    "- AdaBoost: 0.78\n",
    "\n",
    "AdaBoost has the highest accuracy.\n",
    "\n",
    "Precision\n",
    "- Decision Tree (max_depth 10): 0.67\n",
    "- Random Forest: 0.79\n",
    "- AdaBoost: 0.78\n",
    "\n",
    "Random Forest has the highest precision, meaning it is the best at predicting a hotel cancellation. Precision is an important metric in situations where incorrectly predicting would be a sigifnicant issue. For example, in this situation, if the model incorrectly predicted that a hotel booking would be cancelled, it would be an issue for the hotel with overbookings.\n",
    "\n",
    "Recall\n",
    "- Decision Tree (max_depth 10): 0.55\n",
    "- Random Forest: 0.55\n",
    "- AdaBoost: 0.62\n",
    "\n",
    "AdaBoost has the highest recall value. It is more capable of identify the actual cancellations. Recall is an important metric when needing to identify actual cancellations, such as when actual guest numbers need to be estimated in this situation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145fbb52",
   "metadata": {},
   "source": [
    "I also want to generate the F1 score for these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4041c1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6046511627906976\n",
      "0.6460663293055806\n",
      "0.6852199947480602\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, predictions)\n",
    "print(f1)\n",
    "\n",
    "rf_f1 = np.mean(cross_val_score(rf_model, X, y, cv=kfold, scoring='f1'))\n",
    "ada_f1 = np.mean(cross_val_score(ada_model, X, y, cv=kfold, scoring='f1'))\n",
    "\n",
    "print(rf_f1)\n",
    "print(ada_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7437232",
   "metadata": {},
   "source": [
    "F1 Score\n",
    "- Decision Tree (max_depth 10): 0.60\n",
    "- Random Forest: 0.65\n",
    "- AdaBoost: 0.69\n",
    "\n",
    "AdaBoost has the highest F1 score, which means it has the best balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2b39b9",
   "metadata": {},
   "source": [
    "Choosing different metrics is important when evaluating models based on what is important to the problem we are predicting. For instance, for hotel booking cancellations, you could argue that precision is more important as it would impact the hotel negatively to predict a hotel cancellation when it is not actually cancelled. Therefore, when choosing the best model, the one with the highest precision should be chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f57f41e",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b07a796",
   "metadata": {},
   "source": [
    "# XGBoost Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3f3102c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "992a51be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing X and y\n",
    "X = data.drop('is_canceled', axis=1).values\n",
    "y = data['is_canceled'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1fe188cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train 80% and Test 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6155e044",
   "metadata": {},
   "source": [
    "Baseline XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ca833ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7566666666666666\n",
      "0.722055501969295\n",
      "0.6171654533251496\n"
     ]
    }
   ],
   "source": [
    "#Initializing xgboost model\n",
    "xgb_model = xgboost.XGBClassifier(random_state = 5)\n",
    "\n",
    "#k-fold cross validation\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state = 5)\n",
    "\n",
    "#Metrics\n",
    "xgb_accuracy = np.mean(cross_val_score(xgb_model, X, y, cv=kfold, scoring='accuracy'))\n",
    "xgb_precision = np.mean(cross_val_score(xgb_model, X, y, cv=kfold, scoring='precision'))\n",
    "xgb_recall = np.mean(cross_val_score(xgb_model, X, y, cv=kfold, scoring='recall'))\n",
    "\n",
    "print(xgb_accuracy)\n",
    "print(xgb_precision)\n",
    "print(xgb_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a093d5",
   "metadata": {},
   "source": [
    "# Parameters Chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b57c9",
   "metadata": {},
   "source": [
    "1. max_depth\n",
    "\n",
    "Max_depth determines the depth of the tree. A higher value means a deeper tree model, which has a risk of overfitting. A smaller value can prevent the model from memorizing relationships within the data.\n",
    "\n",
    "2. n_estimators\n",
    "\n",
    "N_estimators is the number of trees that will be built before the predictions are made. Higher number of trees can increase performance but also can make the model more complex.\n",
    "\n",
    "3. learning_rate\n",
    "\n",
    "This is the weight of the trees in the model. When the eta is smaller, there will be more tree, which can lead to more accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc5b43d",
   "metadata": {},
   "source": [
    "# Hyperparameter Experimenting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4481230",
   "metadata": {},
   "source": [
    "I decided to use the grid search strategy to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0c22d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d89d7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "parameters = {\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "#Metrics\n",
    "metrics = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "536c9fd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n",
      "Best Parameters:  {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 300}\n",
      "Accuracy:  0.7972222222222222\n",
      "Precision: 0.8469055023923445\n",
      "Recall: 0.604394879275314\n"
     ]
    }
   ],
   "source": [
    "#Grid search implementations\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=parameters, scoring=metrics, cv=kfold, refit='accuracy', verbose=1, return_train_score=True)\n",
    "\n",
    "#Fitting the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "Best parameters and best score\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "#best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters: \", best_params)\n",
    "\n",
    "#accuracy\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Accuracy: \", best_score)\n",
    "\n",
    "#getting the index of the best parameters to get the other metrics\n",
    "best_index = grid_search.best_index_\n",
    "\n",
    "precision = cv_results['mean_test_precision'][best_index]\n",
    "recall = cv_results['mean_test_recall'][best_index]\n",
    "\n",
    "print(\"Precision:\" ,precision)\n",
    "print(\"Recall:\" ,recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a66d3cb",
   "metadata": {},
   "source": [
    "The ideal parameters are:\n",
    "\n",
    "- max_depth: 5\n",
    "- learning_rate: 0.01\n",
    "- n_estimators: 300\n",
    "\n",
    "The metrics I am using are accuracy, precision, and recall.\n",
    "\n",
    "XGBoost metrics\n",
    "- Accuracy: 0.797\n",
    "- Precision: 0.847\n",
    "- Recall: 0.6\n",
    "\n",
    "Accuracy\n",
    "- Decision Tree (max_depth 10): 0.72\n",
    "- Random Forest: 0.77\n",
    "- AdaBoost: 0.78\n",
    "\n",
    "\n",
    "Precision\n",
    "- Decision Tree (max_depth 10): 0.67\n",
    "- Random Forest: 0.79\n",
    "- AdaBoost: 0.78\n",
    "\n",
    "\n",
    "Recall\n",
    "- Decision Tree (max_depth 10): 0.55\n",
    "- Random Forest: 0.55\n",
    "- AdaBoost: 0.62\n",
    "\n",
    "Comparing the accuracy, preicision, and recall to the other models implemented, it seems as though XGBoost with the tuned hyperparameters has the best performance. This shows the importance of the hyperparameters and finding the ideal ones for a specifc model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
